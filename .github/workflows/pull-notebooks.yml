name: Pull Notebooks from Azure Databricks  
  
on:  
  schedule:  
    - cron: "0 0 * * *" # Runs daily at midnight UTC  
  workflow_dispatch: # Allows manual triggering from GitHub Actions  
  
env:  
  # Relative path to the Databricks workspace directory to export  
  DATABRICKS_WORKSPACE_DIR: "/Workspace/Users/admin@mngenvmcap684248.onmicrosoft.com/Primary/.github"  
  LOCAL_EXPORT_DIR: ".github" # Local export directory in the GitHub repository  
  
jobs:  
  pull-notebooks:  
    runs-on: ubuntu-latest  
  
    steps:  
      # Step 1: Checkout the GitHub repository  
      - name: Checkout repository  
        uses: actions/checkout@v3  
  
      # Step 2: Set up Python environment for Databricks CLI  
      - name: Set up Python  
        uses: actions/setup-python@v4  
        with:  
          python-version: "3.x"  
  
      # Step 3: Install Databricks CLI  
      - name: Install Databricks CLI  
        run: |  
          pip install databricks-cli  
  
      # Step 4: Export Notebooks from Databricks Workspace with authentication  
      - name: Export Notebooks  
        env:  
          DATABRICKS_HOST: "https://adb-1192531318314324.4.azuredatabricks.net"  
          DATABRICKS_TOKEN: "dapi9f33ac2e1e2128bf66bc282a41e11428-3"  
          WORKSPACE_DIR: ${{ env.DATABRICKS_WORKSPACE_DIR }}  
          EXPORT_DIR: ${{ env.LOCAL_EXPORT_DIR }}  
        run: |  
          echo "Exporting notebooks from Databricks workspace directory: $WORKSPACE_DIR"  
          echo "Exporting to local directory: $EXPORT_DIR"  
  
          # Ensure the export directory exists  
          mkdir -p $EXPORT_DIR  
  
          # Export notebooks from the specified workspace directory  
          databricks workspace export_dir --profile=DEFAULT $WORKSPACE_DIR $EXPORT_DIR --overwrite  
